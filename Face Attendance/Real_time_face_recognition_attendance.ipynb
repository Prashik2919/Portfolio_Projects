{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import cv2 import numpy as np import face_recognition import os from\n",
    "datetime import datetime\n",
    "\n",
    "# from PIL import ImageGrab\n",
    "\n",
    "path = ‘ImagesAttendance’ images = \\[\\] classNames = \\[\\] myList =\n",
    "os.listdir(path) print(myList) for cl in myList: curImg =\n",
    "cv2.imread(f’{path}/{cl}’) images.append(curImg)\n",
    "classNames.append(os.path.splitext(cl)\\[0\\]) print(classNames)\n",
    "\n",
    "def findEncodings(images): encodeList = \\[\\] for img in images: img =\n",
    "cv2.cvtColor(img, cv2.COLOR_BGR2RGB) encode =\n",
    "face_recognition.face_encodings(img)\\[0\\] encodeList.append(encode)\n",
    "return encodeList\n",
    "\n",
    "def markAttendance(name): with open(‘Attendance.csv’, ‘r+’) as f:\n",
    "myDataList = f.readlines() nameList = \\[\\] for line in myDataList: entry\n",
    "= line.split(‘,’) nameList.append(entry\\[0\\]) if name not in nameList:\n",
    "now = datetime.now() dtString = now.strftime(‘%H:%M:%S’)\n",
    "f.writelines(f’,{dtString}’)\n",
    "\n",
    "#### FOR CAPTURING SCREEN RATHER THAN WEBCAM\n",
    "\n",
    "# def captureScreen(bbox=(300,300,690+300,530+300)):\n",
    "\n",
    "# capScr = np.array(ImageGrab.grab(bbox))\n",
    "\n",
    "# capScr = cv2.cvtColor(capScr, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "# return capScr\n",
    "\n",
    "encodeListKnown = findEncodings(images) print(‘Encoding Complete’)\n",
    "\n",
    "cap = cv2.VideoCapture(1)\n",
    "\n",
    "while True: success, img = cap.read() \\# img = captureScreen() imgS =\n",
    "cv2.resize(img, (0, 0), None, 0.25, 0.25) imgS = cv2.cvtColor(imgS,\n",
    "cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    facesCurFrame = face_recognition.face_locations(imgS)\n",
    "    encodesCurFrame = face_recognition.face_encodings(imgS, facesCurFrame)\n",
    "\n",
    "    for encodeFace, faceLoc in zip(encodesCurFrame, facesCurFrame):\n",
    "        matches = face_recognition.compare_faces(encodeListKnown, encodeFace)\n",
    "        faceDis = face_recognition.face_distance(encodeListKnown, encodeFace)\n",
    "        # print(faceDis)\n",
    "        matchIndex = np.argmin(faceDis)\n",
    "\n",
    "        if matches[matchIndex]:\n",
    "           name = classNames[matchIndex].upper()\n",
    "           # print(name)\n",
    "           y1, x2, y2, x1 = faceLoc\n",
    "           y1, x2, y2, x1 = y1 * 4, x2 * 4, y2 * 4, x1 * 4\n",
    "           cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "           cv2.rectangle(img, (x1, y2 - 35), (x2, y2), (0, 255, 0), cv2.FILLED)\n",
    "           cv2.putText(img, name, (x1 + 6, y2 - 6), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 255, 255), 2)\n",
    "           markAttendance(name)\n",
    "\n",
    "    cv2.imshow('Webcam', img)\n",
    "    cv2.waitKey(1)"
   ],
   "id": "42a14256-91c8-446e-92a7-ab6bf11055d3"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
